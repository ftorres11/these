%--------------------------------------------------------------------------------------------------
\addchap{Introduction}
%\addcontentsline{toc}{chapter}{Introduction}
Human curiosity has led to the desire of understanding the world we inhabit, prompting us to seek
explanations for the phenomena we encounter. We derive this understanding from the information 
we gather through sensory processing. Since most of the sensory information humans process pertains 
to vision, it could be argued that we live within a visual world. Conversely, this human curiosity 
has led to the development of technologies that have fundamentally altered the world: we have 
drastically changed our surroundings by building and adapting them to our needs. Moreover, societal 
development has been closely intertwined with technology: on one hand, the first human settlements 
date back to the surge of agriculture; while on the other hand, the industrial revolution started 
paving the world towards the modern era.\\

\paragraph{Computation and Computer Vision} Currently, one technology that has taken prominence is 
computation, as it affects our lives directly and indirectly. This can be seen in our reliance on 
devices such as computers and  cellphones. These products are the result of scientific breakthroughs 
and innovation. Nevertheless, to do science we need to process information, for which we have 
developed disciplines like mathematics and physics; which in turn can be aided with computation. 
Conversely, innovation within the last century has propelled computation further with the emergence 
of electronic computers. Aided by improvements in transistors and the rapid development of 
microprocessors, computers have become faster, smaller and more accessible; allowing for their 
adoption within society. In recent years, this technology has undergone a revolution with the surge 
and popularization of \emph{Artificial Intelligence} (AI), a promising field with endless 
possibilities for changing and improving human lives.\\

\noindent One particular field where Artificial Intelligence displays promise is \emph{Computer 
Vision}. Computer vision aims to replicate human capabilities with a machine. This endeavor 
can be understood alongside three axes: \emph{Recognition}, \emph{Reorganization} and 
\emph{Reconstruction} \autocite{malik2016three}; the three fundamental tasks of this discipline.
Through recognition, we identify and assign semantic values to elements in our environment. 
Conversely, according to their characteristics or concepts they display, we regroup elements 
in space via regrouping. Finally, through reconstruction we identify elements in a scene, producing 
a model of the external world. In computer vision, we employ models to approximate these axes. 
Moreover, with the adoption of AI in computer vision, the capabilities of these models to emulate 
human vision have increased drastically, leading to their adoption in tasks such as recognition of 
individuals, processing of mail and medical diagnosis. In this thesis we  take special interest in 
the task of image recognition. On one hand, it is the dimension that is the easiest to understand. 
On another hand, given its simplicity, it is used to prototype and produce methodologies 
intersecting the complementary dimensions of computer vision study.\\

\noindent Computer Vision is one major field where modern AI has impacted greatly, shown by the 
progress it has seen in the last decade. In particular, with Convolutional Neural Networks (CNNs); a 
breakthrough on image recognition occurred. Efficient computation of this 
operation enabled its usage on larger collections of data, allowing computer vision models to 
improve their capabilities. Furthermore, these models have benefitted from constant development, in 
turn allowing to perform more complex tasks over time. On one hand, this has led to the creation 
of technologies robust enough to build autonomous vehicles. In the other hand, complex tasks such  
as medical diagnosis are receiving AI tools to facilitate their performance. More recently, a 
breakthrough has taken place with the introduction of the transformer architecture. 
In particular, this architecture allows for a high degree of abstraction, successively avoiding 
issues that convolutions face as inductive bias and difficulties  towards generalization. As a 
result of this, transformer have overcome convolutions in terms of performance but complexity as 
well. Consequently, its no longer so much a question whether \textit{can a model achieve a given 
task?}, but rather a question on \textit{how can this model perform this task?}. The main 
issue regarding these questions lies within the size and complexity of deep models, where 
providing interpretable explanations has lead to the surge of a novel field of research 
(\cite{li2018deep}, \cite{guidotti2018survey}, \cite{bodria2021benchmarking}), interpretability 
and explainable AI.\\

\paragraph{Explainable AI} Following the permeation of intelligent vision systems into society and 
their direct impact into human lives; understanding their inner-working and limitations has become 
critical. In particular, since their complexity has increased alongside their performance, we are 
interested in unfolding this property in order to answer questions regarding their outputs; 
specially when failure cases can negatively affect a life. For instance, considering the medical 
practice and the involvement of AI in automated diagnosis, a misdiagnosis of a pathology can 
potentially derive in an incorrect treatment and loss of life. This is originally referred to as the 
\emph{Desiredata of Interpretability Research}, first proposed in \emph{The Mythos of Model 
Interpretability} \autocite{mythos_interp}. Furthermore, in this work Lipton establishes the 
different properties a model should present in order to be considered interpretable: Transparency 
and Post-Hoc Interpretability. Current Interpretability research is grouped alongside these 
two properties.\\

\noindent Lipton suggests that a transparent model is one that can be summarized or explained 
in its entirely using few words or operations. However, due to the complexity displayed by current 
computer vision models, providing such interpretations for a model is challenging. In particular, 
we observe that most AI models nowadays contain parameters often counted in millions if not 
billions. Additionally, the computation of the sequence of operations requiring these parameters 
to produce an output is also complex in the sense that a forward pass often requires $10^9$ 
operations \autocite{openai_compute}. On a more active manner, \emph{Transparency} can be attained 
by the introduction of modifications to a model or its training procedure 
\autocite{zhang2021survey}. Several works achieve this with the introduction of small decision 
trees to summarize the forward pass of a model; as well as with the addition of regularization terms 
during training encouraging elements of the model to represent semantic concepts.\\

%Moreover, achieving this kind of interpretability is 
%done via the introduction of small modifications on top of the model or its training process. 


\noindent Regarding post-hoc interpretability, Lipton suggests to leverage upon the complex 
structure of models and consequently provide explanations utilizing the already existing parameters 
within the network. This approach in turn allows for a large variance in methodologies since 
information can be extracted in a plethora of different manners in current CNNs and transformers. 
Moreover, this variance of explanations can be observed in the nature of the explanation itself: 
post-hoc interpretations are often presented via text as captions, and in images as in 
saliency maps, to name a few. Nevertheless, it is important to highlight that since explanations 
are computed to highlight relevant information describing the inference process of a model, they 
might not be aligned to what a human would consider following the same questioning. For instance, 
an individual might identify the whiskers and ears of a cat as its defining characteristic; but 
a model can conversely highlight the snoot or eyes instead. On top of this, we note that post-hoc 
interpretations can be obtained for any class a model considers; be it the correct one pertaining 
to an object of interest or one completely unrelated. Still, on practice researchers tend to focus 
on the first case mentioned, while we note that instances where a model fails to provide a correct 
prediction should the ones where interest should be focused on.\\


\paragraph{These objectives}
\paragraph{Dissertation Outline}
%\addcontentsline{toc}{section}{Dissertation Outline}
\noindent This dissertation is aimed towards the development of interpretable image recognition 
models and is organized in the following manner: In Chapter \ref{ch:rel} we 
introduce a background for image recognition models (Section \ref{rel:sec_imrecon}) and the ensuing 
approaches developed to study the interpretability on them (Section \ref{rel:sec_int}). 
Additionally, we introduce evaluation procedures for these approaches which will be further used to 
evaluate our proposals.\\

\noindent In Chapter \ref{ch:opticam}, we propose Opti-CAM as a methodology that generates 
optimized saliency maps highlighting the relevant regions on an image towards image classification. 
In Section \ref{sec:av_gain} we extend existing evaluation metrics with a novel measurement for 
model confidence. On Sections \ref{sec:oc_qual} and \ref{sec:oc_quant} we evaluate the effect of 
these contributions towards interpretability assessment. Opti-CAM overall presents an approach that 
highlights saliency relating to the classifier, thus the saliency map generated performs the best 
in terms of interpretability metrics although is not highly aligned to human interpretations. 
On top of this, our novel metric \emph{Average Gain} acts as a complement to current approaches, \\


\noindent Chapter \ref{ch:castream} introduces the Cross Attention Stream, an approach that boosts 
existing architectures interpretable properties. We set up the modulus of this approach in 
Section \ref{sec:ca_defn} alongside its deployment on Section \ref{sec:ca_design}. 
In Sections \ref{sec:ca_qual} and \ref{sec:ca_quant} we demonstrate the benefits of using this
proposal.\\

\noindent Chapter \ref{ch:grad} characterizes a gradient denoising approach with a gradient denoising 
methodology as an approach to enhance the training procedure of current models while improving 
interpretability properties. In Section \ref{sec:grad_defn}, we define the gradient denoising 
protocol alongside the regularization proposals to do so.
Sections \ref{sec:grad_qual} and \ref{sec:grad_quant} illustrate the effects of this paradigm
in the trained models and its effects on interpretability.\\
    
\noindent Finally, we draw conclusions on our work and detail future research perspectives.
%Human curiosity has led to the desire for understanding the world that we inhabit, producing 
%explanations for the phenomena we experience. We derive this understanding from the information 
%that we gather via the processing of sensory information. Nevertheless, sensory information is 
%handled differently according to its nature; chemical responses are usually linked to the 
%sense of taste and smell, while on another hand physical changes in the environment in proximity 
%are measured via touch, hearing and sight. In particular, visual stimuli is of particular 
%importance given its abundance and its capacity to provide insight into events from a plethora 
%of sources: visually we reliably navigate our environments in our daily life, as well as 
%visually researchers are trying to track the origin of the universe via observations of distant 
%galaxies in the night sky. As a result of this reliance on visual information it can be stated 
%that we live in a visual world.\\

%\noindent Visual information can not only be processed by humans but used to record events. On 
%one hand, most of the understanding of the natural world's history and phenomena is obtained 
%by the processing of natural records: for instance, the history of the earth's formation and 
%evolution can be read from the fossil registry found in ancient rocks. In addition to this, 
%most of human evolution is stored in a visual manner, by studying ancient remains researchers 
%have tracked the first human beings to come from Africa, conversely; the expansion of humanity 
%around the globe is also tracked relying on queues left by our ancestors.
%Amongst the sensory information that the brain processes, visual stimuli accounts 
%for 90\% of data analyzed (\cite{potter2014detecting}), while consuming a great amount of energy 
%in human metabolism (\cite{phelps1981metabolic}). It is argued that a big influence on the 
%brain evolution was as a result of improving the capacity to process this kind of data and the 
%ensuing  pattern recognition (\cite{mattson2014superior}). 
%In current time, these shapes and forms have evolved too: it is no longer common for a human
%the need to scan the environment for faces that could reveal a potential predator; for a change, 
%the patterns that we now seek to unravel also contain products of our own imagination: digits and 
%characters, geometrical shapes.\\

%\noindent The evolution of these patterns did not occur as an isolated process: 
%over time, humans have developed and created new technologies, leading to an interchange of 
%information not found in the natural world. Throughout human history, humans have 
%advanced on the construction of objects and concepts based on data and emerging needs left behind 
%by previous generations. As time progressed, this took humans to new boundaries: covering more 
%distance in shorter time spans, recording and preserving memories for thousands of years, enabling 
%the capacity to safely navigate at night, harvest the power of the atom and most impressively, 
%putting a man on the moon.\\
%Moreover, human development is seen to be intertwined with the technologies introduced 
%at different parts in history. In particular pivotal moments in human history are highlighted by 
%changes in the standard of living: on the agricultural revolution, humankind adopted a sedentary 
%lifestyle and started forming fixed communities; conversely during the industrial revolution, 
%standardization and urbanization led to yet another lifestyle change and a population increase 
%never seen before. In recent times, with the advent of computation another revolution is currently 
%underway, the Artificial Intelligence revolution.\\

%\noindent Building on last century's advancements, computation is a rather recent field although 
%one with endless potential and a thriving research community. Led by the curiosity to understand 
%the world we inhabit, vision is also approached in the computational level; in this Computer Vision 
%field, researchers aim at replicating human capabilities with a machine. In particular, these 
%capabilities can be observed alongside foundational tasks: recognition, grouping and reconstuction
%\autocite{malik2016three}. Following this proposal, we take particular interest in the task of 
%image recognition, the process in which we produce models to align image information with 
%semantic concepts.\\
%Computer science has enjoyed from constant development over time; on one hand, hardware 
%capabilities and performance has enjoyed an steady increase \autocite{schaller1997moore}, allowing 
%machines to perform more complex tasks. Furthermore, since information is being constantly recorded 
%and categorized, these models have been severely dependent on the quality of quantity of data 
%available to achieve their objectives. One pivotal moment towards the improvement of Computer 
%Vision models occured with the introduction of the internet. With this technology, data has become 
%decentralized and information is readily available.\\

%\noindent Taking into consideration the aforementioned  increase on  both compute power and data 
%availability, image recognition models have been steadily adopted and assimiliated within society; 
%nowadays its no longer so much a question \textit{whether can a model achieve a given task}, but 
%rather a question on \textit{how can this given model perform this task}. The main issue regarding 
%these questions lies within the size and complexity of deep models, where providing interpretable 
%explanations has lead to the surge of a novel field of research (\cite{li2018deep}, 
%\cite{guidotti2018survey}, \cite{bodria2021benchmarking}), interpretability and explainable AI.