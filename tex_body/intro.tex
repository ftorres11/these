    \chapter*{Introduction}
    \chaptertoc{}

    \addcontentsline{toc}{chapter}{Introduction}
    \section*{Motivation}
    %\addcontentsline{toc}{section}{Motivation}

    \section*{Dissertation Outline}
    %\addcontentsline{toc}{section}{Dissertation Outline}
    This dissertation is organized in the following manner: First
    we introduce a background on existing approaches towards interpretability of image
    recognition models; for that, we make mention on current architectures dedicated 
    to this approach, while also presenting concepts on interpretability and enunciating 
    current approaches for this study. 

    In Chapter \ref{ch:opticam}, we propose Opti-CAM as a methodology that generates 
    optimized saliency maps highlighting the relevant regions on an image towards image
    classification. On Section \ref{sec:av_gain} we extend existing evaluation metrics 
    with a novel measurement for model coinfidence. extends evaluation metrics with the 
    introduction of a novel measurement yielding improvements on model confidence 
    when using a given attribution approach. On Sections \ref{sec:oc_qual, sec:oc_quant} 
    we evaluate the effect of these contributions towards interpretability assessment.
    
    Chapter \ref{ch:castream} introduces the Cross Attention Stream, an approach that boosts
     existing architectures interpretable properties. We ste up the modulus of this approach 
    on Section \ref{sec:ca_defn} alongside its deployment on Section \ref{sec:ca_design}. 
    On Sections \ref{sec:ca_qual} and \ref{sec:ca_quant} we demonstrate the benefits 
    of using this proposal.
    
    Chapter \ref{ch:grad} characterizes a gradient denoising approch with a gradient denoising
     methodology as an approach to enhance the trainining procedure of current
    models while improving interpretability properties. On Section \ref{sec:grad_defn}, 
    we define the gradient denoising protocol alongside the regularization proposals to do so.
    Sections \ref{sec:grad_qual, sec:grad_quant} illustrate the effects of this paradigmn
    on the trained models and its effects on interpretability.
    
    Chapter \ref{ch:zip} raises the Zero-Information algorithm and its usage as a substitute
    for mask-dependent evaluation proposals. Section \ref{sec:zip_algo} develops this 
    method. Section \ref{sec:zip_insdel} demonstrates its incorporation of this 
    algorithm onto evaluation protocols. Section \ref{sec:zip_qual} displays
    the effect of this approach when applied to mask patches on images. Section 
    \ref{sec:zip_benchmark} displays the results of benchmarking these protocols 
    with this approach. 
    
    Finally, 
    we draw conclusions on our work and detail future research perspectives.

