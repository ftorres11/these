%--------------------------------------------------------------------------------------------------
\section{Conclusion}
%% Check
In this chapter, we propose a transparency methodology that improves interpretability properties 
of \glspl{cnn}, by denoising the gradient on the input level. Our approach constrains the 
gradient calculated through backpropagation, aligning this information in the input space with a 
refined representation obtained through guided backpropagation.\\

\noindent We validate our claims on improvement of interpretability properties using a post-hoc 
interpretability evaluation procedure. We find that our methodology not only 
improves these properties but also boosts recognition performance. However, we 
observe that an optimized version of this study better suited for larger collections of data and 
more complex models is desired. Further research is desired to address these limitations.
For instance, an optimization of our training paradigm reducing its computational cost, would 
make the method more scalable.
