%--------------------------------------------------------------------------------------------------
\section{Experiments}
This section presents the experimental settings, our evaluation metrics and results.
%Finally, we present qualitative and quantitative results and an ablation study.\\

\subsection{Experimental Set-up}
In the following sections, we evaluate recognition properties and interpretability capabilities of 
our approach. Specifically, we generate explanations following popular attribution methods derived 
from CAM \autocite{zhou2016learning} from the \textbf{pytorch-grad-cam} library from Jacob 
Gildenblat\footnote{https://github.com/jacobgil/pytorch-grad-cam}.

\paragraph{Dataset}
We train and evaluate our models on CIFAR-100 \autocite{krizhevsky2009learning}. This dataset 
contains 60,000 images of 100 categories, split in 50,000 for training and 10,000 for testing. Each 
image has a resolution of $32\times32$ pixels. This dataset is chosen because of its ease of usage 
and prototyping properties. 

\paragraph{Settings}
To obtain competitive performance and ensure the replicability of our method, we follow the 
methodology found in the repository by weiaicunzai 
\footnote{https://github.com/weiaicunzai/pytorch-cifar100}. Thus, we train each model following the 
same training procedure. We perform 200 epochs, with a starting learning rate of $10^{-1}$, a 
batch-size of 128 images, SGD optimizer and a learning rate policy updating said parameter by 
division over 5 on epochs 60, 120 and 160.  
