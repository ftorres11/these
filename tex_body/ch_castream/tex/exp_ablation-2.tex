\subsection{Ablation}
\label{sec:gen_ablation}

To make sense of our approach, we conduct ablation experiments on interpretable recognition tasks. For these experiments, we opt to experiment on ResNet50 because of its modularity and ease of modification. First, we demonstrate the differences between the possible variations of the CA-Block, then we experiment with the placement of said  mechanism on a given backbone alongside its effects on interpretability, continuing with an study of the interpretability capabilities of the attention branch, to finish, we remonstrate a comparison between our chosen approach when training from  pretrained weights and scratch.

%------------------------------------------------------------------------------

\paragraph{Cross attention block design}

Following transformers~\cite{NIPS2017_3f5ee243,dosovitskiy2020image}, it is possible to add more layers in the cross attention block. We consider two variants. One, referred to as \PO, uses linear projections $W_\ell^K, W_\ell^V \in \real^{d_\ell \times d_\ell}$ on the key and value
\begin{equation}
	\ca_\ell(\vq_\ell, F_\ell) \defn (F_\ell W^V_\ell)\tran h_\ell(F_\ell W^K_\ell \vq_\ell)\in \real^{d_\ell}.
\label{eq:proj_ca}
\end{equation}
In another variant, referred to as \OM, an MLP follows each cross attention block, defined as
\begin{equation}
	\mlp_\ell(\vq_\ell) = W_\ell^2 \gelu(W_\ell^1 \vq_\ell + b_\ell^1) + b_\ell^2,
\label{eq:mlp_ca}
\end{equation}
where $W_\ell^1 \in \real^{2d_\ell \times d_\ell}$ and $W_\ell^1 \in \real^{d_\ell \times 2d_\ell}$. In both cases, equation~\eq{qk-layer} remains. The combination of the two variants is referred to as \POM.


We compare the effect on accuracy when adding one of the variants to the backbone (just after the last residual block). \autoref{tab:CA_variations} demonstrates this assessment.

%------------------------------------------------------------------------------
\begin{table}
\centering
%\resizebox{\columnwidth}{!}{%
\scriptsize
\begin{tabular}{lcc}\\\toprule
	\Th{Block Type}&\Th{$\#$Params}&\Th{Acc}\\\midrule
	CA&4.20M&74.63\\
	Proj$\rightarrow$CA&12.58M&74.19\\
	CA$\rightarrow$MLP&20.97M&-\\
	Proj$\rightarrow$CA$\rightarrow$MLP&29.36M&-\\\bottomrule
\end{tabular}
%}
\vspace{3pt}
\caption{Comparison of classification performance when one cross attention block is added into the last residual block of ResNet-50.}
\label{tab:CA_variations}
\end{table}
%------------------------------------------------------------------------------

We observe that the introduction of the basic design of the cross attention module outperforms the classification properties of that which uses projection of the input features to compute the subsequent representation. We hypothesize that maintaining the features without any projection allows the [class] token to better collect global information, as patch information is maintained in the same space that the already trained classifier relies on to perform classification. 
On another hand, we also note that the introduction of an MLP to update said representation is not feasible given instability during training, for this reason we decide not to pursue further experimentation with this idea.
%We observe that there is a notable difference in performance between the adoption of the basic block and that which has projections for the features that are used to compute the subsequent representation. However, we hypothesize that this difference is due in large manner because of the parameter overhead for the feature projection. Moreover, we also note that introducing an MLP to update the representation computed in the attention mechanism is not possible given instability during training, for this reason we consider that further experimentation with this variant is not desired given the nature of the idea.% towards providing a lightweight manner to produce interpretable recognition.

%------------------------------------------------------------------------------
\begin{table}
\centering
\scriptsize
%\resizebox{\columnwidth}{!}{%}
\begin{tabular}{lcc}\toprule
	\Th{Block Type}&\Th{$\#$Params}&\Th{Accuracy}\\\midrule
	CA&6.96M&74.70\\
	Proj$\rightarrow$CA&18.13M&74.41\\\bottomrule
\end{tabular}
%}
\vspace{3pt}
\caption{Comparison of classification performance for CLS-Streams using different CA block designs using ResNet-50 as backbone}
\label{tab:dif_streams}
\end{table}
%------------------------------------------------------------------------------

%Moving on, we experiment with the inclusion of a stream of CA blocks alongside the backbone. For this, we place a block whenever we increase the dimensionality of features at different residual blocks. As noted on Table \ref{tab:dif_streams}, we observe that while a single CA block with feature projections performs better than one without them, however, the aggregation of multiple basic CA blocks produces better results than the aforementioned proposal, while also reducing the amount of trainable parameters. In the spirit of providing explanations in a simple and straightforward manner, we conduct our experimentation with the basic CA design.
% On another hand, we point the sharp contrast in the parameter count when we add more operations to this mechanism,  it is combining this observation with the idea of providing explanations for a given model in a straightforward manner, that we opt to build the CLS-Stream on the simplest manner possible. For this reason, for the rest of the paper we choose this version by default.
Moving on, we experiment with the CLS-Stream using either CA-block proposal. As noted on \autoref{tab:dif_streams}, we observe that the stream made of basic CA blocks performs better than that which uses projections for the attention mechanism. Moreover, we observe that this aggregation of CA blocks remains lightweight and overall improves the performance for the aforementioned block design. On top of this, we also note that most of the computation weight lies within the last residual stages, as it depends directly on the channel dimension which is largest in these depths. In the spirit of providing explanations in a simple and straightforward manner, we conduct our experimentation with the basic CA design.

%------------------------------------------------------------------------------

\paragraph{\Ours placement}
\label{ab:placement}

To validate the design of \Ours, we measure the effect of its depth on its performance \vs the baseline \gap in terms of both classification accuracy / number of parameters and classification metrics for interpretability. In particular, we place the stream in parallel to the network $f$, starting at stage $\ell$ and running through stage $L$, the last stage of $f$, where $0 \le \ell \le L$. Results are reported in \autoref{tab:intrecog-resnet}.

\textbf{Check}

%------------------------------------------------------------------------------
\begin{table}
\centering
\scriptsize
\setlength{\tabcolsep}{4pt}
%\resizebox{\columnwidth}{!}{%}
\begin{tabular}{lcccccc}\toprule
	\mc{7}{\Th{Accuracy and Parameters}}\\\midrule
	&\Th{Placement}&\mc{2}{\Th{CLS dim}}&\mc{2}{\Th{\#Param}}&\Th{Acc}\\\midrule
	
	&$S_0-S_4$&\mc{2}{$64$}  &\mc{2}{6.96M}&\textbf{74.70}\\  % 6.963.264
	&$S_1-S_4$&\mc{2}{$256$} &\mc{2}{6.95M}&74.67\\           % 6.947.072
	&$S_2-S_4$&\mc{2}{$512$} &\mc{2}{6.82M}&74.67\\           % 6.816.256
	&$S_3-S_4$&\mc{2}{$1024$}&\mc{2}{6.29M}&74.67\\           % 6.292.480
	&$S_4-S_4$&\mc{2}{$2048$}&\mc{2}{4.20M}&74.63\\\midrule   % 4.196.352
	
	\mc{7}{\Th{Interpretability Metrics}}\\\midrule
	\Th{Method}&\Th{Placement}&\Th{AD$\downarrow$}&\Th{AG$\uparrow$}&\Th{AI$\uparrow$}&\Th{I$\uparrow$}&\Th{D$\downarrow$}\\\midrule
	
	\mr{5}{\Th{Grad-CAM}}&$S_0-S_4$&\textbf{12.54}&\blue{22.67}&\blue{48.56}&75.53&13.50\\ % Checked
		&$S_1-S_4$&12.69&22.65&48.31&75.53&13.41\\ % Checked
		&$S_2-S_4$&\textbf{12.54}&21.67&\textbf{48.58}&75.54&13.50\\ % Running
		&$S_3-S_4$&12.69&22.28&47.89&\blue{75.55}&\textbf{13.40}\\ % Running
		&$S_4-S_4$&12.77&20.65&47.14&74.32&13.37\\\midrule % Checked
		
	\mr{5}{\Th{Grad-CAM++}}&$S_0-S_4$&13.99&19.29&\blue{44.60}&75.21&13.78\\ % Checked
		&$S_1-S_4$&13.99&19.29&\textbf{44.62}&75.21&13.78\\ % Checked
		&$S_2-S_4$&\blue{13.71}&\blue{19.90}&45.43&75.34&\blue{13.50}\\ % Running
		&$S_3-S_4$&\textbf{13.69}&19.61&45.04&\blue{75.36}&\blue{13.50}\\ % Running
		&$S_4-S_4$&13.67&18.36&44.40&74.190&13.30\\\midrule % Checked
		
	\mr{5}{\Th{Score-CAM}}&$S_0-S_4$&\blue{7.09}&23.65&54.20&74.91&14.68\\ % Checked
		&$S_1-S_4$&\blue{7.09}&23.65&54.20&\blue{74.92}&14.68\\ % Checked
		&$S_2-S_4$&\blue{7.09}&\blue{23.66}&54.21&74.91&14.68\\ % Running
		&$S_3-S_4$&7.74&23.03&\blue{52.92}&\textbf{74.97}&\blue{14.65}\\ % Running
		&$S_4-S_4$&Check&Check&Check&Check&Check\\\bottomrule % Checked
\end{tabular}
% }
\vspace{3pt}
\caption{\emph{Effect of stream placement} on accuracy, parameters and interpretability metrics of \Ours \vs baseline \gap for ResNet-50 and different interpretability methods on ImageNet. $S_\ell-S_L$: \Ours runs from stage $\ell$ to $L$ (last); \Th{$\#$Param}: parameter or \Ours only; Bold: best per method per metric.}
\label{tab:intrecog-resnet}
\end{table}
%------------------------------------------------------------------------------

From the different class activation mappings interpretability results, we observe that the stream configuration that interacts the most with the backbone obtains the best metrics overall, taking into consideration the classification performance. On another hand, we take special notice on the performance when using the lightest stream of only one CA block. We note that its interpretable properties present a sharp contrast when compared to those of different approaches, presenting remarkable improvements in terms of AG, Ins and Del; and notable losses in terms of AD and AI. We place special consideration on the results obtained for Score-CAM, as for it the difference in performance increases for all methods when compared to CA on R$_4$ alone.%; having improvements of 3, 16 and 6 points for AD, AG, AI respectively.

%------------------------------------------------------------------------------

\paragraph{Class-agnostic CLS}

As mentioned on \autoref{subsec:motiv}, we observed that while there is a difference between CAM-based saliency maps ~\eq{sal} and attention ~\eq{connection}, it is possible to extend ~\eq{connection} using a query vector per class, making it class specific. For this goal, during training we forward the weight vector relating to the groundtruth class for a given image, and during inference we forward the weight vector related to the predicted class by the backbone. This way, during training we update the [class] tokens according to the groundtruth labels in the minibatch.

%------------------------------------------------------------------------------
\begin{table}
\centering
\scriptsize
\setlength{\tabcolsep}{2.5pt}
%\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllccccc}\toprule                    
	Repr&Accuracy&Method&AD$\downarrow$&AG$\uparrow$&AI$\uparrow$&I$\uparrow$&D$\downarrow$\\\midrule
	% \multirow{3}{*}{GAP}&\multirow{3}{*}{74.55}&Grad-CAM&13.04&17.56&44.47&72.57&13.24\\
	%  & &Grad-CAM++&13.79&15.87&42.08&72.32&13.33\\
	%  & &Score-CAM&13.64&12.98&44.53&62.56&11.37\\\hline %
	\multirow{3}{*}{CLS$_T$}&\multirow{3}{*}{74.70}&Grad-CAM&12.54&22.67&48.56&75.53&13.50\\
		& &Grad-CAM++&13.99&19.29&44.60&75.21&13.78\\
		& &Score-CAM&7.09&23.65&54.20&74.91&14.68\\\midrule
		\multirow{3}{*}{CLS$_M$}&\multirow{3}{*}{74.68}&Grad-CAM&12.53&22.66&48.58&75.54&13.50\\
		& &Grad-CAM++&13.99&19.28&44.62&75.20&13.78\\
		& &Score-CAM&TBA&TBA&TBA&TBA&TBA\\\bottomrule
\end{tabular}
%}
\vspace{3pt}
\caption{Interpretable recognition comparison between Class agnostic tokens (\emph{CLS$_T$}) and Class specific tokens (\emph{CLS$_M$}).}
\label{tab:TokenvMatrix}
\end{table}
%------------------------------------------------------------------------------

\autoref{tab:TokenvMatrix} presents a comparison of the CLS-Stream using class agnostic and class specific representations. We observe that presenting a class dependent representation for the CLS Stream to learn, provides no remarkable diferences when compared with the standard class agnostic representation. Similar to \cite{touvron2021augmenting} our class dependent representation is capable of providing independent class maps, however to do so we do not require any fine-tuning whatsoever. 
% For these reasons and in hopes of maintaining a simple approach

%------------------------------------------------------------------------------

\paragraph{Stream attention interpretability}

Based on equation \ref{eq:connection} and inspired by \cite{abnar2020quantifying}, we note that we can visualize the flow of information across the CLS-Stream for every CA block. Nevertheless, from the aforementioned work, we find that Attention Rollout is not so desired given complications in its calculation. On \autoref{fig:compmethods} we observe some differences between Attention and different CAM proposals. % Define Attention
% With this in mind we first demonstrate the similarities between Grad-CAM and Raw Attention in Figure \ref{fig:rawatt_gradcam}.
% Conversely, following the similarity between CAM methods and attention, we observe that attention can be used to compute saliency maps. We present the similarities for these kinds of visualizations in figure \ref{fig:rawatt_gradcam}

% \begin{figure}[H]
%     \centering
%     % \resizebox{\columnwidth}{!}{%
%     \begin{tabular}{cccc}
%         {}&Input Image & Grad-CAM & Raw Attention\\
%         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
%         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
%         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
%     \end{tabular}
%     % }
%     \caption{Visual comparison between Grad-CAM and Raw Attention}
%     \label{fig:rawatt_gradcam}
% \end{figure}

Moving on, we evaluate these attention maps following the approach for interpretable recognition. As noted on \autoref{tab:rawatt_gradcam}, raw attention presents a similar if not a bit worse performance in comparison to Grad-CAM. It could be argued that according to the similarities between CAM based approaches and attention ones described in ~\eq{connection}, a direct comparison is plausible; although not proper, knowing that raw attention uses softmax as non-linearity.

%------------------------------------------------------------------------------
\begin{table}
\centering
\scriptsize
%\resizebox{\columnwidth}{!}{%}
\begin{tabular}{lccccc}\toprule
		\Th{Method}&\Th{AD}$\downarrow$&\Th{AG$\uparrow$}&\Th{AI$\uparrow$}&\Th{I$\uparrow$}&\Th{D$\downarrow$}\\\midrule
		Raw-Attention&13.42&15.76&41.48&73.86&16.29\\
		Grad-CAM&12.54&22.67&48.56&75.53&13.50\\\bottomrule
\end{tabular}
%}
\vspace{3pt}
\caption{Comparison of interpretable performance between Raw Attention and Grad-CAM}
\label{tab:rawatt_gradcam}
\end{table}
%------------------------------------------------------------------------------


%% Top design, bottom interp metrics
%% More parts for experiments

% Ablation of histogram of diferences with extreme cases
