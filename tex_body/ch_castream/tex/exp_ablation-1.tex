    \subsection{Ablation}
    \label{sec:gen_ablation}
    To make sense of our approach, we conduct ablation experiments on interpretable recognition tasks. For these experiments, we opt to experiment on ResNet50 because of its modularity and ease of modification. First, we demonstrate the differences between the possible variations of the CA-Block, then we experiment with the placement of said  mechanism on a given backbone alongside its effects on interpretability, continuing with an study of the interpretability capabilities of the attention branch, to finish, we remonstrate a comparison between our chosen approach when training from  pretrained weights and scratch.

    \paragraph{Cross Attention block proposals}
    Following the proposals for the CA block found on \autoref{subsec:variations}, we compare the effect on accuracy when adding one of them to the backbone (just after the last residual block). \autoref{tab:CA_variations} demonstrates this assessment.
    
    \begin{table}[H]
        \centering
        %\resizebox{\columnwidth}{!}{%
        \scriptsize
        %\resizebox{5.5cm}{!}{%
        %\resizebox{\columnwidth}{!}{%}
        \begin{tabular}{lcc}\\\toprule
             \Th{Block Type}&\Th{$\#$Params}&\Th{Acc}\\\midrule
             CA&4.20M&74.63\\
             Proj$\rightarrow$CA&12.58M&74.19\\
             CA$\rightarrow$MLP&20.97M&-\\
             Proj$\rightarrow$CA$\rightarrow$MLP&29.36M&-\\\bottomrule
        \end{tabular}
        %}
        \caption{Comparison of classification performance when one cross attention block is added into the last residual block of ResNet-50.}
        \label{tab:CA_variations}
    \end{table}
    %To start with the proposals for the CA-block,
    We observe that the introduction of the basic design of the cross attention module outperforms the classification properties of that which uses projection of the input features to compute the subsequent representation. We hypothesize that maintaining the features without any projection allows the [class] token to better collect global information, as patch information is maintained in the same space that the already trained classifier relies on to perform classification. 
    On another hand, we also note that the introduction of an MLP to update said representation is not feasible given instability during training, for this reason we decide not to pursue further experimentation with this idea.
    %We observe that there is a notable difference in performance between the adoption of the basic block and that which has projections for the features that are used to compute the subsequent representation. However, we hypothesize that this difference is due in large manner because of the parameter overhead for the feature projection. Moreover, we also note that introducing an MLP to update the representation computed in the attention mechanism is not possible given instability during training, for this reason we consider that further experimentation with this variant is not desired given the nature of the idea.% towards providing a lightweight manner to produce interpretable recognition.
    \begin{table}[H]
        \centering
        \scriptsize
        %\resizebox{5.5cm}{!}{%
        %\resizebox{\columnwidth}{!}{%}
        \begin{tabular}{lcc}\toprule
             \Th{Block Type}&\Th{$\#$Params}&\Th{Accuracy}\\\midrule
             CA&6.96M&74.70\\
             Proj$\rightarrow$CA&18.13M&74.41\\\bottomrule
        \end{tabular}
        %}
        \caption{Comparisson of classification performance for CLS-Streams using different CA block designs using ResNet-50 as backbone}
        \label{tab:dif_streams}
    \end{table}
    %Moving on, we experiment with the inclusion of a stream of CA blocks alongside the backbone. For this, we place a block whenever we increase the dimensionality of features at different residual blocks. As noted on Table \ref{tab:dif_streams}, we observe that while a single CA block with feature projections performs better than one without them, however, the aggregation of multiple basic CA blocks produces better results than the aforementioned proposal, while also reducing the amount of trainable parameters. In the spirit of providing explanations in a simple and straightforward manner, we conduct our experimentation with the basic CA design.
    % On another hand, we point the sharp contrast in the parameter count when we add more operations to this mechanism,  it is combining this observation with the idea of providing explanations for a given model in a straightforward manner, that we opt to build the CLS-Stream on the simplest manner possible. For this reason, for the rest of the paper we choose this version by default.
    Moving on, we experiment with the CLS-Stream using either CA-block proposal. As noted on \autoref{tab:dif_streams}, we observe that the stream made of basic CA blocks performs better than that which uses projections for the attention mechanism. Moreover, we observe that this aggregation of CA blocks remains lightweight and overall improves the performance for the aforementioned block design. On top of this, we also note that most of the computation weight lies within the last residual stages, as it depends directly on the channel dimension which is largest in these depths. In the spirit of providing explanations in a simple and straightforward manner, we conduct our experimentation with the basic CA design.


    %% Under revision from here
    \paragraph{CLS-Stream design}
    \label{ab:placement}
    %To assess the effect of the placement of the CA blocks, we conduct experiments across the width the model, varying the starting point for this approach; departing from the first residual block onto the last residual block. For this family of experiments we evaluate accuracy and interpretability metrics (reported on tables \ref{tab:acc_tab} and \ref{tab:intrecog-resnet}) , as it is in our best interest to obtain a model that preserves if not improves the classification performance, while providing enhanced explanations.
    To validate the design of the CLS-Stream, we conduct experiments across the depth the model; varying the starting point for this approach: departing from the first residual stage onto the last residual one. For this family of experiments we evaluate accuracy and interpretability metrics reported on \autoref{tab:intrecog-resnet}, as it is in our best interest to obtain a model that preserves if not improves the classification performance, while providing enhanced explanations.
    % \begin{table}[H]
    %     \centering

    %     \caption{Classification metrics for ResNet-50 with different CLS stream propositions.}
    %     \label{tab:acc_tab}
    % \end{table}
    %Regarding classification performance, we report the CA module placements, the CLS token starting dimension and the total parameter count and accuracy values.
    \textbf{Check}
    %We observe that there is a stark difference between on accuracy when comparing a CLS stream made up of multiple CA blocks, and one composed of solely one; this difference is clearer when we compare the two simplest CLS streams, (R$_3\rightarrow\mbox{R}_4$) and (R$_4$). We hypothesize that one possible explanation for these discrepancies lies within the complexity of training the CLS token and the amount of interactions that it can have with the features flowing from the backbone. Following this, we observe that having a deeper stream allows for a smaller classification token to be learnt, as by design its dimensions are projected to those in the following stages in the backbone to support attention computation.  We argue that the more communication with features, the more CLS can learn, alongside its projections. %We argue that this contrast in performance takes into consideration more interactions between the CLS token %it is important to note that the increment in trainable parameters is found alongside the depth of the network. We observe that the layers that present a larger quantity of parameters are found out closer to the classifier

    % Following the focus on interpretability evaluation, we generate saliency maps for each of the aforementioned models and we evaluate them on terms of AD, AG, IC, Ins and Del. Results are reported on Table \ref{tab:intrecog-resnet}
    \begin{table}[t]
        \centering
        \scriptsize
        \setlength{\tabcolsep}{2.5pt}
        %\resizebox{\columnwidth}{!}{%}
        \begin{tabular}{cccccc}\toprule
             Placement&CLS Dimension&\#Params&Accuracy\\\midrule
             $\mbox{R}_0\rightarrow\mbox{R}_4$&$1\times64$&6.963.264&\textbf{74.70}\\
             $\mbox{R}_1\rightarrow\mbox{R}_4$&$1\times256$&6.947.072&74.67\\
             $\mbox{R}_2\rightarrow\mbox{R}_4$&$1\times512$&6.816.256&74.67\\
             $\mbox{R}_3\rightarrow\mbox{R}_4$&$1\times1024$&6.292.480&74.67\\
             $\mbox{R}_4\rightarrow\mbox{R}_4$&$1\times2048$&4.196.352&74.63\\\bottomrule
        \end{tabular}
        %}
        
        \bigskip
        %\resizebox{\columnwidth}{!}{%
        \begin{tabular}{llccccc}\toprule
            \Th{Method}&\Th{Placement}&\Th{AD$\downarrow$}&\Th{AG$\uparrow$}&\Th{AI$\uparrow$}&\Th{I$\uparrow$}&\Th{D$\downarrow$}\\\midrule
            \mr{5}{\Th{Grad-CAM}}&$\mbox{R}_0-\mbox{R}_4$&\textbf{12.54}&\blue{22.67}&\blue{48.56}&75.53&13.50\\ % Checked
             &$\mbox{R}_1-\mbox{R}_4$&12.69&22.65&48.31&75.53&13.41\\ % Checked
             &$\mbox{R}_2-\mbox{R}_4$&\textbf{12.54}&21.67&\textbf{48.58}&75.54&13.50\\ % Running
             &$\mbox{R}_3-\mbox{R}_4$&12.69&22.28&47.89&\blue{75.55}&\textbf{13.40}\\ % Running
             &$\mbox{R}_4-\mbox{R}_4$&12.77&20.65&47.14&74.32&13.37\\\hline % Checked
            \mr{5}{\Th{Grad-CAM++}}&$\mbox{R}_0-\mbox{R}_4$&13.99&19.29&\blue{44.60}&75.21&13.78\\ % Checked
             &$\mbox{R}_1-\mbox{R}_4$&13.99&19.29&\textbf{44.62}&75.21&13.78\\ % Checked
             &$\mbox{R}_2-\mbox{R}_4$&\blue{13.71}&\blue{19.90}&45.43&75.34&\blue{13.50}\\ % Running
             &$\mbox{R}_3-\mbox{R}_4$&\textbf{13.69}&19.61&45.04&\blue{75.36}&\blue{13.50}\\ % Running
             &$\mbox{R}_4-\mbox{R}_4$&13.67&18.36&44.40&Check&Check\\\hline % Checked
            \mr{5}{\Th{Score-CAM}}&$\mbox{R}_0-\mbox{R}_4$&\blue{7.09}&23.65&54.20&74.91&14.68\\ % Checked
             &$\mbox{R}_1-\mbox{R}_4$&\blue{7.09}&23.65&54.20&\blue{74.92}&14.68\\ % Checked
             &$\mbox{R}_2-\mbox{R}_4$&\blue{7.09}&\blue{23.66}&54.21&74.91&14.68\\ % Running
             &$\mbox{R}_3-\mbox{R}_4$&7.74&23.03&\blue{52.92}&\textbf{74.97}&\blue{14.65}\\ % Running
             &$\mbox{R}_4-\mbox{R}_4$&Check&Check&Check&Check&Check\\\bottomrule % Checked
        \end{tabular}
       % }
        \caption{\emph{Recognition metrics for ResNet-50 and CLS stream design.} \textbf{Top} Stream design and classification metrics. \textbf{Bottom} Interpretable Recognition Metrics with the addition of the CLS stream across different stages of the network.}% We report the interpretable recognition metrics obtained by varying placement of the CLS stream from the first to the last residual blocks it receives features from.}
        \label{tab:intrecog-resnet}
    \end{table}

    % To begin with, we observe that 
    From the different class activation mappings interpretability results, we observe that the stream configuration that interacts the most with the backbone obtains the best metrics overall, taking into consideration the classification performance. On another hand, we take special notice on the performance when using the lightest stream of only one CA block. We note that its interpretable properties present a sharp contrast when compared to those of different approaches, presenting remarkable improvements in terms of AG, Ins and Del; and notable losses in terms of AD and AI. We place special consideration on the results obtained for Score-CAM, as for it the difference in performance increases for all methods when compared to CA on R$_4$ alone.%; having improvements of 3, 16 and 6 points for AD, AG, AI respectively.
    % Until here
    \paragraph{Class Agnostic CLS}
    As mentioned on \autoref{subsec:motiv}, we observed that while there is a difference between CAM-based saliency maps ~\eq{sal} and attention ~\eq{connection}, it is possible to extend ~\eq{connection} using a query vector per class, making it class specific. For this goal, during training we forward the weight vector relating to the groundtruth class for a given image, and during inference we forward the weight vector related to the predicted class by the backbone. This way, during training we update the [class] tokens according to the groundtruth labels in the minibatch.

    \begin{table}[H]
        \centering
        \scriptsize
        \setlength{\tabcolsep}{2.5pt}
        %\resizebox{\columnwidth}{!}{%
        \begin{tabular}{lllccccc}\toprule                    
            Repr&Accuracy&Method&AD$\downarrow$&AG$\uparrow$&AI$\uparrow$&I$\uparrow$&D$\downarrow$\\\midrule
            % \multirow{3}{*}{GAP}&\multirow{3}{*}{74.55}&Grad-CAM&13.04&17.56&44.47&72.57&13.24\\
            %  & &Grad-CAM++&13.79&15.87&42.08&72.32&13.33\\
            %  & &Score-CAM&13.64&12.98&44.53&62.56&11.37\\\hline %
            \multirow{3}{*}{CLS$_T$}&\multirow{3}{*}{74.70}&Grad-CAM&12.54&22.67&48.56&75.53&13.50\\
             & &Grad-CAM++&13.99&19.29&44.60&75.21&13.78\\
             & &Score-CAM&7.09&23.65&54.20&74.91&14.68\\\midrule
             \multirow{3}{*}{CLS$_M$}&\multirow{3}{*}{74.68}&Grad-CAM&12.53&22.66&48.58&75.54&13.50\\
             & &Grad-CAM++&13.99&19.28&44.62&75.20&13.78\\
             & &Score-CAM&TBA&TBA&TBA&TBA&TBA\\\bottomrule
        \end{tabular}
        %}
        \caption{Interpretable recognition comparison between Class agnostic tokens (\emph{CLS$_T$}) and Class specific tokens (\emph{CLS$_M$}).}
        \label{tab:TokenvMatrix}

    \end{table}

    \autoref{tab:TokenvMatrix} presents a comparison of the CLS-Stream using class agnostic and class specific representations. We observe that presenting a class dependent representation for the CLS Stream to learn, provides no remarkable diferences when compared with the standard class agnostic representation. Similar to \cite{touvron2021augmenting} our class dependent representation is capable of providing independent class maps, however to do so we do not require any fine-tuning whatsoever. 
    % For these reasons and in hopes of maintaining a simple approach

    \paragraph{Stream Attention Interpretability}
    Based on equation \ref{eq:connection} and inspired by \cite{abnar2020quantifying}, we note that we can visualize the flow of information across the CLS-Stream for every CA block. Nevertheless, from the aforementioned work, we find that Attention Rollout is not so desired given complications in its calculation. On \autoref{fig:compmethods} we observe some differences between Attention and different CAM proposals. % Define Attention
    % With this in mind we first demonstrate the similarities between Grad-CAM and Raw Attention in Figure \ref{fig:rawatt_gradcam}.
    % Conversely, following the similarity between CAM methods and attention, we observe that attention can be used to compute saliency maps. We present the similarities for these kinds of visualizations in figure \ref{fig:rawatt_gradcam}

    % \begin{figure}[H]
    %     \centering
    %     % \resizebox{\columnwidth}{!}{%
    %     \begin{tabular}{cccc}
    %         {}&Input Image & Grad-CAM & Raw Attention\\
    %         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
    %         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
    %         % {\rotatebox{90}{classname}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}&{\includegraphics[width=0.15\textwidth]{}}\\
    %     \end{tabular}
    %     % }
    %     \caption{Visual comparison between Grad-CAM and Raw Attention}
    %     \label{fig:rawatt_gradcam}
    % \end{figure}

    Moving on, we evaluate these attention maps following the approach for interpretable recognition. As noted on \autoref{tab:rawatt_gradcam}, raw attention presents a similar if not a bit worse performance in comparison to Grad-CAM. It could be argued that according to the similarities between CAM based approaches and attention ones described in ~\eq{connection}, a direct comparison is plausible; although not proper, knowing that raw attention uses softmax as non-linearity.

    \begin{table}[H]
        \centering
        \scriptsize
        %\resizebox{\columnwidth}{!}{%}
        \begin{tabular}{lccccc}\toprule
             \Th{Method}&\Th{AD}$\downarrow$&\Th{AG$\uparrow$}&\Th{AI$\uparrow$}&\Th{I$\uparrow$}&\Th{D$\downarrow$}\\\midrule
             Raw-Attention&13.42&15.76&41.48&73.86&16.29\\
             Grad-CAM&12.54&22.67&48.56&75.53&13.50\\\bottomrule
        \end{tabular}
        %}
        \caption{Comparison of interpretable performance between Raw Attention and Grad-CAM}
        \label{tab:rawatt_gradcam}
    \end{table}

    % Can be deleted if so
    \paragraph{Training from Scratch}
    % Rephrasing to make emph on post-hoc and argue that while it is possible, acc is not dropped too much. It's more interesting to do post-hoc (...) sic.
    % Other comparisons, SCOUTER. Maybe play with Conformer

    One of the latest observations from our approach answers to the question \textit{what would happen if we trained each model from scratch?}. Following existing training regime for ResNet50, we begin by training a baseline model which will be a replica of that found off the shelf; we make use of this model as a control further down the experimentation. Then we train a model with the CLS stream in a similar fashion. We present the evolution of the training error in \autoref{fig:scratch_freeze}

    \begin{figure}[H]
        \centering
            \begin{tikzpicture}
                \begin{axis}[width=\columnwidth,height=2in, no markers, xlabel=epoch, ylabel=error,
                            grid=both, grid style={line width=.1pt, draw=gray!10}, major grid style={line width=.2pt,draw=gray!50},]
                    [xlabel = epochs,
                    ylabel = top1 err]
                    \addplot table [x=epoch, y=top1err, col sep=comma, mark=none] {Data/r50base_scratch.csv};
                    \addplot table [x=epoch, y=top1err, col sep=comma, mark=none] {Data/r50stream_scratch.csv};
                    \addplot table [x=epoch, y=top1err, col sep=comma, mark=none] {Data/r50stream_shelf.csv};
                    \legend{Backbone,
                            Backbone+Stream,
                            Stream}
                \end{axis}
             \end{tikzpicture}
        \label{fig:scratch_freeze}
        \caption{Curves of training procedure on ImageNet-1k for ResNet50 for the baseline model (blue) vs baseline and CLS-stream (red) and just training the stream. We show the top-1 training error for the different approaches.}
    \end{figure}

    Moreover, these differences are better quantified with the \textbf{(WIP)}

    %% Top design, bottom interp metrics
    %% More parts for experiments

    % Ablation of histogram of diferences with extreme cases