%--------------------------------------------------------------------------------------------------
\paragraph{Object localization}
\label{sec:oc_loc}
Localization metrics are used to measure the precision of saliency maps relative to groundtruth 
bounding boxes of the foreground object of interest. These metrics originate from weakly supervised 
localization (WSOL). However, the objectives of WSOL and explaining the decision of a DNN are not 
necessarily aligned, since context may play an important role in the decision (\cite{shetty2019not}, 
\cite{rao2022towards}).\\

\noindent To investigate the relative importance of the object and its context, we measure 
classification metrics when using the bounding box $B$ itself as a saliency map as well as its 
complement $I \setminus B$, where $I$ is the image. We also evaluate the intersection $B \cap S$ 
of the saliency map $S$ with the bounding box and with its complement ($S \setminus B$).\\

\noindent As shown in \autoref{tab:localization}, the ground truth region of the object is not the 
only one responsible for the network decision. For example, the bounding box fails both when used 
as a saliency map itself and when combined with any saliency map, by harming all classification 
metrics. Even the complement is more effective than the bounding box itself, either alone or when 
combined. These findings support the hypothesis that localization metrics based on the ground truth 
bounding box are not necessarily appropriate for evaluating explanations of network decisions. 
Classification metrics are clearly more appropriate in this sense.\\

%\noindent Nevertheless, we report localization metrics in the supplementary material. In summary, 
%although its saliency maps are more spread out, Opti-CAM outperforms other methods on a number of 
%metrics.
%--------------------------------------------------------------------------------------------------
\input{tab/opticam/tex/table_loc_cnn_imagenet.tex}
%--------------------------------------------------------------------------------------------------
\subsection{Weakly Supervised Approach}
\label{sec:oc_wsol}
Several works measure the localization ability of saliency maps, using metrics from the \emph{weakly
-supervised object localization} (WSOL) task. While we show that localization of the object and 
classifier interpretability are not well aligned as tasks, we still provide localization results. 
We use the \emph{official metric} (OM), \emph{localization error} (LE), \emph{pixel-wise $F_1$ 
score}, \emph{box accuracy} (BoxAcc) \autocite{choe2020evaluating}, standard pointing game (SP) 
\autocite{zhang2018top}, \emph{energy pointing game} (EP) \autocite{wang2020score} and 
\emph{saliency metric} (SM) \autocite{dabkowski2017real} on the ILSVRC2014\footnote{\url{
https://www.image-net.org/challenges/LSVRC/2014/index\#}} dataset. 
The goal of these metrics is to compare the saliency maps with bounding boxes around the object 
of interest. \\

\noindent We evaluate the localization ability of saliency maps obtained by our Opti-CAM and we 
compare with other attribution methods quantitatively. \autoref{tab:imagenet-loc} and 
\autoref{tab:ablate-loc-sup-deit} report localization metrics on ImageNet. We observe different 
behavior in different metrics. In particular, Opti-CAM on ResNet and VGG performs best on OM and 
LE but poorly on the remaining metrics. On transformers, Opti-CAM performs best on OM, LE, F1, and 
SM.\\

%--------------------------------------------------------------------------------------------------
\input{tab/opticam/tex/table_loc_ext_cnn_imagenet.tex}
\input{tab/opticam/tex/table_deit.tex}
%--------------------------------------------------------------------------------------------------

\noindent Metrics, where Opti-CAM does not perform well, are mostly the ones that penalize saliency 
maps that are more spread out. For example, SP and EP penalize saliency outside the ground truth 
bounding box of an object. This is not necessarily a weakness of Opti-CAM, because rather than 
weakly supervised object localization, the objective here is to explain how the classifier works.