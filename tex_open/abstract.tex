%--------------------------------------------------------------------------------------------------
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
Computer Vision applications using Artificial Intelligence technologies have undergone a remarkable 
evolution in the past decade. Current developments in Computer Vision are a direct result of a 
better utilization of hardware, enabling the construction of models capable of performing more 
complex tasks over time. On image recognition in particular, convolutional neural networks and 
transformers are now able to identify images and their elements, as well as assign semantic value 
to them, even in challenging conditions. These models have completely changed the landscape of deep 
learning and image recognition, permeating deep into society with the automatization of many daily 
tasks.\\

\noindent With the permeation of deep learning technologies within society, a new requirement 
emerged for these methodologies. Since they are now interacting and affecting human lives directly, 
it is mandatory to understand their functioning and provide explanations. To address these 
questions a new research field has emerged: interpretability and explainable AI.\\

%--------------------------------------------------------------------------------------------------
\noindent In this thesis, our goal is to understand and further develop interpretability models for 
state-of-the-art image recognition models. We introduce and briefly explain some of the most 
relevant high performance image recognition models for both Convolutional Neural Networks 
and Transformers. Then, current interpretability approaches designed to provide 
explanations, as well as their evaluation protocols. We make observations upon 
these methods and evaluation protocols, highlighting difficulties upon them and suggesting ideas 
to address their limitations. In the following chapters we present our contributions.\\

%--------------------------------------------------------------------------------------------------
\paragraph{Opti-CAM} Our first contribution, builds upon the reasoning of Class Activation 
Mappings. In particular, this proposal optimizes the weighting coefficient required to compute a 
saliency map, generating a representation that maximizes class specific probability.  This saliency 
map performs the best across interpretability metrics on multiple datasets.  Plus, it highlights 
that context is relevant towards describing a prediction. Additionally, a novel metric to complement 
interpretability evaluation is unveiled, addressing shortcomings in this procedure.\\

%--------------------------------------------------------------------------------------------------
\paragraph{Cross Attention Stream}  Our second contribution, is an addition to current image 
recognition models, enhancing interpretability measurements. Inspired novel high performing models 
such as Transformers, we construct a stream that computes the interaction of an abstract class 
representation, with deep features of convolutional neural networks. This representation is 
ultimately used to perform classification. Our Stream displays improvements on quantitative 
evaluation, as well as preserves recognition performance across different models.\\

%--------------------------------------------------------------------------------------------------
\paragraph{Gradient Denoising} Lastly, our final contribution presents a novel training paradigm 
for deep neural networks. Moreover, this paradigm denoises the gradient information of deep models 
in the input space. The guided backpropagation representation of the input image is used to 
regularize models during their training phase. As a result, our trained models display improvements 
for interpretable evaluation. We apply our paradigm to small architectures in a constrained 
setting, paving the way for future development in large scale datasets, as well as with more 
complex models.\\

\vspace{0.5cm}
Keywords: Deep Learning, image recognition, interpretability, explainability.

