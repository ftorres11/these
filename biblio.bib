% Grad-CAM++
@inproceedings{chattopadhay2018grad,
    author = {A. Chattopadhay and A. Sarkar and P. Howlader and V. N. Balasubramanian},
    booktitle = {WACV},
    title = {Grad-{CAM}++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks},
    year = {2018},
    volume = {},
    issn = {},
    keywords = {visualization;heating systems;neurons;machine learning;predictive models;mathematical model},
}

% WSOL Evaluation
@inproceedings{choe2020evaluating,
    title = {Evaluating Weakly Supervised Object Localization Methods Right},
    author={Choe, Junsuk and Oh, Seong Joon and Lee, Seungho and Chun, Sanghyuk and Akata, Zeynep and Shim, Hyunjung},
    booktitle = {CVPR},
    year = {2020}
} 

% Top-Down Neural Attention
@article{zhang2018top,
    title={Top-Down Neural Attention by Excitation Backprop},
    volume={126},
    journal={IJCV},
    author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
    year={2017},
    pages={1084-1102}
}

% Score-CAM 
@inproceedings{wang2020score,
    author = {Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
    title = {Score-{CAM}: Score-Weighted Visual Explanations for Convolutional Neural Networks},
    booktitle = {CVPR Workshop},
    year = {2020}
} 

% Real Time Saliency for BB Classifiers
@article{dabkowski2017real,
    author = {Dabkowski, Piotr and Gal, Yarin},
    journal = {NIPS},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    publisher = {Curran Associates, Inc.},
    title = {Real Time Image Saliency for Black Box Classifiers},
    year = {2017}
}

% ADAM optimizer
@article{kingma2014adam,
    author    = {Diederik P. Kingma and
                Jimmy Ba},
    editor    = {Yoshua Bengio and
                Yann LeCun},
    title     = {Adam: {A} Method for Stochastic Optimization},
    journal = {ICLR},
    year      = {2015},
}

% RISE, Ins-Del
@article{petsiuk2018rise,
  title = {RISE: Randomized Input Sampling for Explanation of Black-box Models},
  author = {Vitali Petsiuk and Abir Das and Kate Saenko},
  journal = {BMVC},
  year = {2018}
}

% Perturbation
@inproceedings{fong2017interpretable,
    author = {Fong, Ruth C. and Vedaldi, Andrea},
    title = {Interpretable Explanations of Black Boxes by Meaningful Perturbation},
    booktitle = {ICCV},
    year = {2017}
} 

% Ex-Perturbation
@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2950--2958},
  year={2019}
}

% Flow-Bottleneck restriction
@article{schulz2020restricting,
  title={Restricting the flow: Information bottlenecks for attribution},
  author={Schulz, Karl and Sixt, Leon and Tombari, Federico and Landgraf, Tim},
  journal={arXiv preprint arXiv:2001.00396},
  year={2020}
}

% LIME
@inproceedings{ribeiro2016should,
    author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
    title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
    year = {2016},
    isbn = {9781450342322},
    booktitle = {SIGKDD},
    keywords = {interpretability, black box classifier, explaining machine learning, interpretable machine learning},
    location = {San Francisco, California, USA},
    series = {KDD '16}
}

% Opti-CAM
@article{zhang2023opti,
  title={Opti-CAM: Optimizing saliency maps for interpretability},
  author={Zhang, Hanwei and Torres, Felipe and Sicre, Ronan and Avrithis, Yannis and Ayache, Stephane},
  journal={arXiv preprint arXiv:2301.07002},
  year={2023}
}

% Transformer + CNN
@inproceedings{bello2019attention,
  title={Attention augmented convolutional networks},
  author={Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3286--3295},
  year={2019}
}

% Stand-Alone SA in vision models
@article{ramachandran2019stand,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% Global SA
@article{shen2020global,
  title={Global self-attention networks for image recognition},
  author={Shen, Zhuoran and Bello, Irwan and Vemulapalli, Raviteja and Jia, Xuhui and Chen, Ching-Hui},
  journal={arXiv preprint arXiv:2010.03019},
  year={2020}
}

% ViT
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

% LeViT
@inproceedings{graham2021levit,
  title={Levit: a vision transformer in convnet's clothing for faster inference},
  author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={12259--12269},
  year={2021}
}

% Early Convs in Transformers
@article{xiao2021early,
  title={Early convolutions help transformers see better},
  author={Xiao, Tete and Singh, Mannat and Mintun, Eric and Darrell, Trevor and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30392--30400},
  year={2021}
}

% Swin-T
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

% SCOUTER
@inproceedings{li2021scouter,
  title={SCOUTER: Slot attention-based classifier for explainable image recognition},
  author={Li, Liangzhi and Wang, Bowen and Verma, Manisha and Nakashima, Yuta and Kawasaki, Ryo and Nagahara, Hajime},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1046--1055},
  year={2021}
}

$ Slot-Attention
@article{locatello2020object,
  title={Object-centric learning with slot attention},
  author={Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

% Conformer
@inproceedings{peng2021conformer,
  title={Conformer: Local features coupling global representations for visual recognition},
  author={Peng, Zhiliang and Huang, Wei and Gu, Shanzhi and Xie, Lingxi and Wang, Yaowei and Jiao, Jianbin and Ye, Qixiang},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={367--376},
  year={2021}
}

% Patchconvnet
@article{touvron2021augmenting,
  title={Augmenting convolutional networks with attention-based aggregation},
  author={Touvron, Hugo and Cord, Matthieu and El-Nouby, Alaaeldin and Bojanowski, Piotr and Joulin, Armand and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2112.13692},
  year={2021}
}

% Rethinking spatial in transformers
@inproceedings{heo2021rethinking,
  title={Rethinking spatial dimensions of vision transformers},
  author={Heo, Byeongho and Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Choe, Junsuk and Oh, Seong Joon},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11936--11945},
  year={2021}
}

% FakeCAM + ADCC
@inproceedings{poppi2021revisiting,
  title={Revisiting the evaluation of class activation mapping for explainability: A novel metric and experimental analysis},
  author={Poppi, Samuele and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2299--2304},
  year={2021}
}

% GradCAM
@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={CVPR},
  year={2017}
}

% Network Inspection
@article{zhou2018interpreting,
  author={Zhou, Bolei and Bau, David and Oliva, Aude and Torralba, Antonio},
  journal={Trans. PAMI}, 
  title={Interpreting Deep Visual Representations via Network Dissection}, 
  year={2019},
  volume={41},
  number={9},
  pages={2131-2145},
 }

% CAM
@inproceedings{zhou2016learning,    
    author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
    title = {Learning Deep Features for Discriminative Localization},
    booktitle = {CVPR},
    year = {2016}
} 

%% Raw-Attention, Rollout Attention
@article{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  journal={arXiv preprint arXiv:2005.00928},
  year={2020}
}

%% TIBAV
@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={782--791},
  year={2021}
}

% Fidelity 
@article{yeh2019fidelity,
  title={On the (in) fidelity and sensitivity of explanations},
  author={Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

%% Review interp
@article{samek2021explaining,
  author={Samek, Wojciech and Montavon, Grégoire and Lapuschkin, Sebastian and Anders, Christopher J. and Müller, Klaus-Robert},
  journal={Proc. of the IEEE}, 
  title={Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications}, 
  year={2021},
  volume={109},
  number={3},
  pages={247-278},
 }

% Evaluation visualization
 @article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}